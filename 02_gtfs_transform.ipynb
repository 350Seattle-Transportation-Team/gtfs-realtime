{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This script combines data from gtfs files from multiple dates. It outputs combined shapes, routes, and trips files. It also outputs an aggregated \"full trip stop schedule\" file, which contains columns from various gtfs input files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-30T20:41:30.814387Z",
     "start_time": "2019-11-30T20:41:29.643398Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-30T20:46:08.874449Z",
     "start_time": "2019-11-30T20:46:08.870453Z"
    }
   },
   "outputs": [],
   "source": [
    "# root directory for all the gtfs data files from different dates\n",
    "#/Users/benjaminmalnor/sandbox/bus350/gtfs-realtime\n",
    "gtfs_folder = \"./data/source/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-30T20:46:09.132450Z",
     "start_time": "2019-11-30T20:46:09.128450Z"
    }
   },
   "outputs": [],
   "source": [
    "# create dictionary keyed by date then file type;\n",
    "# each entry is a pandas dataframe\n",
    "date_file_dict = defaultdict(dict)\n",
    "file_types = ['stops', 'stop_times', 'trips', 'shapes', 'routes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-30T20:46:09.334461Z",
     "start_time": "2019-11-30T20:46:09.330470Z"
    }
   },
   "outputs": [],
   "source": [
    "# specify set of dates to combine\n",
    "# (for a set of files labeled with a certain date, \n",
    "# those data apply from that date up until the day before \n",
    "# the next date for which data files exist)\n",
    "date_start_end_dict = {'20190420':('2019-04-20','2019-05-08'),\n",
    "                       '20190509':('2019-05-09','2019-06-18')\n",
    "                       }\n",
    "dates = list(date_start_end_dict.keys())\n",
    "\n",
    "# make sure to change out_suffix below to correspond to this date range!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-30T20:46:15.111435Z",
     "start_time": "2019-11-30T20:46:10.002450Z"
    }
   },
   "outputs": [],
   "source": [
    "# read in each file type for each date, and store in dictionary\n",
    "for date in dates:\n",
    "    for f in file_types:\n",
    "        file_location = f\"{gtfs_folder}gtfs_{date}/{f}.txt\"\n",
    "        date_file_dict[date][f] = pd.read_csv(file_location)\n",
    "        date_file_dict[date][f]['start_gtfs_date'] = \\\n",
    "            datetime.datetime.strptime(date_start_end_dict[date][0], \"%Y-%m-%d\")\n",
    "        date_file_dict[date][f]['end_gtfs_date'] = \\\n",
    "            datetime.datetime.strptime(date_start_end_dict[date][1], \"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-30T20:46:20.606900Z",
     "start_time": "2019-11-30T20:46:20.598901Z"
    }
   },
   "outputs": [],
   "source": [
    "# get the desired set of columns for the new aggregated \"full trip stop schedule\" file\n",
    "def trip_stop_schedule(gtfs_stops, gtfs_stop_times, gtfs_trips, gtfs_routes):\n",
    "    gtfs_stops.drop(['start_gtfs_date','end_gtfs_date'], axis=1, inplace=True)\n",
    "    trip_stops_w_names = gtfs_stop_times.merge(gtfs_stops, how='left',on='stop_id')\n",
    "    trip_arrival_time = trip_stops_w_names.loc[trip_stops_w_names['stop_sequence']==1,['trip_id','stop_sequence','arrival_time']]\\\n",
    "                        .groupby('trip_id')\\\n",
    "                        .agg({'arrival_time':'max'})\\\n",
    "                        .reset_index()\\\n",
    "                        .rename(columns={'arrival_time':'trip_start_time'})\n",
    "    trip_stops_w_names = trip_stops_w_names.merge(trip_arrival_time, how='left', on='trip_id')\n",
    "    \n",
    "    trip_stops_w_name_route = trip_stops_w_names.merge(gtfs_trips[['trip_id','route_id','direction_id','trip_headsign','shape_id']], how='left',on='trip_id')\n",
    "    \n",
    "    trip_stops_w_name_route = trip_stops_w_name_route.merge(gtfs_routes[['route_id', 'route_short_name', 'route_desc']], how='left', on='route_id')\n",
    "\n",
    "    return trip_stops_w_name_route"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-30T20:46:39.586876Z",
     "start_time": "2019-11-30T20:46:22.883917Z"
    }
   },
   "outputs": [],
   "source": [
    "# for each date, aggregate information from various files\n",
    "file_types.append('aggregated')\n",
    "for date in dates:\n",
    "    date_file_dict[date][file_types[-1]] = trip_stop_schedule(date_file_dict[date]['stops'], \n",
    "                                                              date_file_dict[date]['stop_times'],\n",
    "                                                              date_file_dict[date]['trips'], \n",
    "                                                              date_file_dict[date]['routes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-30T20:46:43.074863Z",
     "start_time": "2019-11-30T20:46:41.750869Z"
    }
   },
   "outputs": [],
   "source": [
    "# append all the data from different dates for each file type \n",
    "# (including the new aggregated file type)\n",
    "file_dict = {}\n",
    "for f in file_types:\n",
    "    file_dict[f] = date_file_dict[dates[0]][f].copy()\n",
    "    for date in dates[1:]:\n",
    "        file_dict[f] = file_dict[f].append(date_file_dict[date][f])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-30T20:46:43.537868Z",
     "start_time": "2019-11-30T20:46:43.509872Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['trip_id', 'arrival_time', 'departure_time', 'stop_id', 'stop_sequence',\n",
       "       'stop_headsign', 'pickup_type', 'drop_off_type', 'shape_dist_traveled',\n",
       "       'start_gtfs_date', 'end_gtfs_date', 'stop_code', 'stop_name',\n",
       "       'stop_desc', 'stop_lat', 'stop_lon', 'zone_id', 'stop_url',\n",
       "       'location_type', 'parent_station', 'stop_timezone', 'trip_start_time',\n",
       "       'route_id', 'direction_id', 'trip_headsign', 'shape_id',\n",
       "       'route_short_name', 'route_desc'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_dict['aggregated'].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-30T20:46:44.793326Z",
     "start_time": "2019-11-30T20:46:44.781356Z"
    }
   },
   "outputs": [],
   "source": [
    "# suffix for the output files specifying the date range they contain; \n",
    "# we could get this from date_start_end_dict \n",
    "# here's a gross way to get min/max date - please make it better :)\n",
    "date_list = []\n",
    "for key, vals in date_start_end_dict.items():\n",
    "    date_list.append(datetime.datetime.strptime(vals[0],\"%Y-%m-%d\"))\n",
    "    date_list.append(datetime.datetime.strptime(vals[0],\"%Y-%m-%d\"))\n",
    "date_list.sort()\n",
    "start_date = date_list[0].strftime(\"%Y-%m-%d\")\n",
    "end_date = date_list[-1].strftime(\"%Y-%m-%d\")\n",
    "out_suffix = f\"{start_date}_{end_date}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-30T20:47:34.351765Z",
     "start_time": "2019-11-30T20:47:34.347764Z"
    }
   },
   "outputs": [],
   "source": [
    "#output folder\n",
    "gtfs_output_folder = \"./data/gtfs_merge/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-30T20:49:45.914503Z",
     "start_time": "2019-11-30T20:47:59.301212Z"
    }
   },
   "outputs": [],
   "source": [
    "# write output csv files\n",
    "file_dict['aggregated'].to_csv(f\"{gtfs_output_folder}gtfs_agg_{out_suffix}.csv\", index=False)\n",
    "file_dict['shapes'].to_csv(f\"{gtfs_output_folder}gtfs_shapes_{out_suffix}.csv\", index=False)\n",
    "file_dict['routes'].to_csv(f\"{gtfs_output_folder}gtfs_routes_{out_suffix}.csv\", index=False)\n",
    "file_dict['trips'].to_csv(f\"{gtfs_output_folder}gtfs_trips_{out_suffix}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_hdf(\"2018_12_01_positions.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "vehicle_id                          object\n",
       "timestamp                           object\n",
       "trip_id                             object\n",
       "route_id                            object\n",
       "vehicle_lat                        float64\n",
       "vehicle_long                       float64\n",
       "time_utc                    datetime64[ns]\n",
       "time_pst        datetime64[ns, US/Pacific]\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vehicle_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>trip_id</th>\n",
       "      <th>route_id</th>\n",
       "      <th>vehicle_lat</th>\n",
       "      <th>vehicle_long</th>\n",
       "      <th>time_utc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time_pst</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-11-30 19:36:03-08:00</th>\n",
       "      <td>6029</td>\n",
       "      <td>1543635363</td>\n",
       "      <td>40422300</td>\n",
       "      <td>102548</td>\n",
       "      <td>47.677052</td>\n",
       "      <td>-122.125549</td>\n",
       "      <td>2018-12-01 03:36:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-11-30 19:36:59-08:00</th>\n",
       "      <td>8213</td>\n",
       "      <td>1543635419</td>\n",
       "      <td>40569902</td>\n",
       "      <td>100169</td>\n",
       "      <td>47.593361</td>\n",
       "      <td>-122.329048</td>\n",
       "      <td>2018-12-01 03:36:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-11-30 19:36:54-08:00</th>\n",
       "      <td>3646</td>\n",
       "      <td>1543635414</td>\n",
       "      <td>40570008</td>\n",
       "      <td>100252</td>\n",
       "      <td>47.678116</td>\n",
       "      <td>-122.325729</td>\n",
       "      <td>2018-12-01 03:36:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-11-30 19:36:27-08:00</th>\n",
       "      <td>3679</td>\n",
       "      <td>1543635387</td>\n",
       "      <td>39683585</td>\n",
       "      <td>100203</td>\n",
       "      <td>47.774464</td>\n",
       "      <td>-122.341980</td>\n",
       "      <td>2018-12-01 03:36:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-11-30 19:37:26-08:00</th>\n",
       "      <td>4403</td>\n",
       "      <td>1543635446</td>\n",
       "      <td>40986086</td>\n",
       "      <td>100173</td>\n",
       "      <td>47.639584</td>\n",
       "      <td>-122.360527</td>\n",
       "      <td>2018-12-01 03:37:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-01 14:51:57-08:00</th>\n",
       "      <td>2681</td>\n",
       "      <td>1543704717</td>\n",
       "      <td>40988679</td>\n",
       "      <td>100447</td>\n",
       "      <td>47.615219</td>\n",
       "      <td>-122.325142</td>\n",
       "      <td>2018-12-01 22:51:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-01 14:51:45-08:00</th>\n",
       "      <td>7230</td>\n",
       "      <td>1543704705</td>\n",
       "      <td>40775297</td>\n",
       "      <td>100113</td>\n",
       "      <td>47.673546</td>\n",
       "      <td>-122.132584</td>\n",
       "      <td>2018-12-01 22:51:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-01 14:51:46-08:00</th>\n",
       "      <td>7091</td>\n",
       "      <td>1543704706</td>\n",
       "      <td>40950107</td>\n",
       "      <td>100249</td>\n",
       "      <td>47.623955</td>\n",
       "      <td>-122.319893</td>\n",
       "      <td>2018-12-01 22:51:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-01 14:51:50-08:00</th>\n",
       "      <td>6210</td>\n",
       "      <td>1543704710</td>\n",
       "      <td>40949377</td>\n",
       "      <td>102576</td>\n",
       "      <td>47.520996</td>\n",
       "      <td>-122.390846</td>\n",
       "      <td>2018-12-01 22:51:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-01 14:52:36-08:00</th>\n",
       "      <td>6224</td>\n",
       "      <td>1543704756</td>\n",
       "      <td>40949378</td>\n",
       "      <td>102576</td>\n",
       "      <td>47.561081</td>\n",
       "      <td>-122.385933</td>\n",
       "      <td>2018-12-01 22:52:36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>299797 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          vehicle_id   timestamp   trip_id route_id  \\\n",
       "time_pst                                                              \n",
       "2018-11-30 19:36:03-08:00       6029  1543635363  40422300   102548   \n",
       "2018-11-30 19:36:59-08:00       8213  1543635419  40569902   100169   \n",
       "2018-11-30 19:36:54-08:00       3646  1543635414  40570008   100252   \n",
       "2018-11-30 19:36:27-08:00       3679  1543635387  39683585   100203   \n",
       "2018-11-30 19:37:26-08:00       4403  1543635446  40986086   100173   \n",
       "...                              ...         ...       ...      ...   \n",
       "2018-12-01 14:51:57-08:00       2681  1543704717  40988679   100447   \n",
       "2018-12-01 14:51:45-08:00       7230  1543704705  40775297   100113   \n",
       "2018-12-01 14:51:46-08:00       7091  1543704706  40950107   100249   \n",
       "2018-12-01 14:51:50-08:00       6210  1543704710  40949377   102576   \n",
       "2018-12-01 14:52:36-08:00       6224  1543704756  40949378   102576   \n",
       "\n",
       "                           vehicle_lat  vehicle_long            time_utc  \n",
       "time_pst                                                                  \n",
       "2018-11-30 19:36:03-08:00    47.677052   -122.125549 2018-12-01 03:36:03  \n",
       "2018-11-30 19:36:59-08:00    47.593361   -122.329048 2018-12-01 03:36:59  \n",
       "2018-11-30 19:36:54-08:00    47.678116   -122.325729 2018-12-01 03:36:54  \n",
       "2018-11-30 19:36:27-08:00    47.774464   -122.341980 2018-12-01 03:36:27  \n",
       "2018-11-30 19:37:26-08:00    47.639584   -122.360527 2018-12-01 03:37:26  \n",
       "...                                ...           ...                 ...  \n",
       "2018-12-01 14:51:57-08:00    47.615219   -122.325142 2018-12-01 22:51:57  \n",
       "2018-12-01 14:51:45-08:00    47.673546   -122.132584 2018-12-01 22:51:45  \n",
       "2018-12-01 14:51:46-08:00    47.623955   -122.319893 2018-12-01 22:51:46  \n",
       "2018-12-01 14:51:50-08:00    47.520996   -122.390846 2018-12-01 22:51:50  \n",
       "2018-12-01 14:52:36-08:00    47.561081   -122.385933 2018-12-01 22:52:36  \n",
       "\n",
       "[299797 rows x 7 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.set_index(\"time_pst\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
