{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This script combines data from gtfs files from multiple dates. It outputs combined shapes, routes, and trips files. It also outputs an aggregated \"full trip stop schedule\" file, which contains columns from various gtfs input files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-13T05:17:58.615805Z",
     "start_time": "2019-06-13T05:17:58.592241Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-13T05:17:59.438666Z",
     "start_time": "2019-06-13T05:17:59.413805Z"
    }
   },
   "outputs": [],
   "source": [
    "# root directory for all the gtfs data files from different dates\n",
    "#/Users/benjaminmalnor/sandbox/bus350/gtfs-realtime\n",
    "gtfs_folder = \"../data/source/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-13T05:17:59.622891Z",
     "start_time": "2019-06-13T05:17:59.602634Z"
    }
   },
   "outputs": [],
   "source": [
    "# create dictionary keyed by date then file type;\n",
    "# each entry is a pandas dataframe\n",
    "date_file_dict = defaultdict(dict)\n",
    "file_types = ['stops', 'stop_times', 'trips', 'shapes', 'routes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-13T05:18:00.039645Z",
     "start_time": "2019-06-13T05:18:00.007827Z"
    }
   },
   "outputs": [],
   "source": [
    "# specify set of dates to combine\n",
    "# (for a set of files labeled with a certain date, \n",
    "# those data apply from that date up until the day before \n",
    "# the next date for which data files exist)\n",
    "date_start_end_dict = {'20180815':('2018-08-15','2018-09-23'),\n",
    "                       '20180924':('2018-09-24','2018-09-24'),\n",
    "                      '20180925':('2018-09-25','2018-11-01'),\n",
    "                      '20181102':('2018-11-02','2018-11-09'),\n",
    "                      '20181110':('2018-11-10','2018-11-28'),\n",
    "                      '20181129':('2018-11-29','2018-12-11'),\n",
    "                      '20181212':('2018-12-12','2019-01-01')}\n",
    "dates = list(date_start_end_dict.keys())\n",
    "\n",
    "# make sure to change out_suffix below to correspond to this date range!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-13T05:18:14.924596Z",
     "start_time": "2019-06-13T05:18:00.524835Z"
    }
   },
   "outputs": [],
   "source": [
    "# read in each file type for each date, and store in dictionary\n",
    "for date in dates:\n",
    "    for f in file_types:\n",
    "        file_location = f\"{gtfs_folder}gtfs_{date}/{f}.txt\"\n",
    "        date_file_dict[date][f] = pd.read_csv(file_location)\n",
    "        date_file_dict[date][f]['start_gtfs_date'] = \\\n",
    "            datetime.datetime.strptime(date_start_end_dict[date][0], \"%Y-%m-%d\")\n",
    "        date_file_dict[date][f]['end_gtfs_date'] = \\\n",
    "            datetime.datetime.strptime(date_start_end_dict[date][1], \"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-13T05:18:41.993000Z",
     "start_time": "2019-06-13T05:18:41.956791Z"
    }
   },
   "outputs": [],
   "source": [
    "# get the desired set of columns for the new aggregated \"full trip stop schedule\" file\n",
    "def trip_stop_schedule(gtfs_stops, gtfs_stop_times, gtfs_trips, gtfs_routes):\n",
    "    gtfs_stops.drop(['start_gtfs_date','end_gtfs_date'], axis=1, inplace=True)\n",
    "    trip_stops_w_names = gtfs_stop_times.merge(gtfs_stops, how='left',on='stop_id')\n",
    "    trip_arrival_time = trip_stops_w_names.loc[trip_stops_w_names['stop_sequence']==1,['trip_id','stop_sequence','arrival_time']]\\\n",
    "                        .groupby('trip_id')\\\n",
    "                        .agg({'arrival_time':'max'})\\\n",
    "                        .reset_index()\\\n",
    "                        .rename(columns={'arrival_time':'trip_start_time'})\n",
    "    trip_stops_w_names = trip_stops_w_names.merge(trip_arrival_time, how='left', on='trip_id')\n",
    "    \n",
    "    trip_stops_w_name_route = trip_stops_w_names.merge(gtfs_trips[['trip_id','route_id','direction_id','trip_headsign','shape_id']], how='left',on='trip_id')\n",
    "    \n",
    "    trip_stops_w_name_route = trip_stops_w_name_route.merge(gtfs_routes[['route_id', 'route_short_name', 'route_desc']], how='left', on='route_id')\n",
    "\n",
    "    return trip_stops_w_name_route"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-13T05:19:21.828040Z",
     "start_time": "2019-06-13T05:18:42.793840Z"
    }
   },
   "outputs": [],
   "source": [
    "# for each date, aggregate information from various files\n",
    "file_types.append('aggregated')\n",
    "for date in dates:\n",
    "    date_file_dict[date][file_types[-1]] = trip_stop_schedule(date_file_dict[date]['stops'], \n",
    "                                                              date_file_dict[date]['stop_times'],\n",
    "                                                              date_file_dict[date]['trips'], \n",
    "                                                              date_file_dict[date]['routes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-13T05:21:25.733259Z",
     "start_time": "2019-06-13T05:20:49.514141Z"
    }
   },
   "outputs": [],
   "source": [
    "# append all the data from different dates for each file type \n",
    "# (including the new aggregated file type)\n",
    "file_dict = {}\n",
    "for f in file_types:\n",
    "    file_dict[f] = date_file_dict[dates[0]][f].copy()\n",
    "    for date in dates[1:]:\n",
    "        file_dict[f] = file_dict[f].append(date_file_dict[date][f])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-13T05:21:25.833351Z",
     "start_time": "2019-06-13T05:21:25.737975Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['trip_id', 'arrival_time', 'departure_time', 'stop_id', 'stop_sequence',\n",
       "       'stop_headsign', 'pickup_type', 'drop_off_type', 'shape_dist_traveled',\n",
       "       'start_gtfs_date', 'end_gtfs_date', 'stop_code', 'stop_name',\n",
       "       'stop_desc', 'stop_lat', 'stop_lon', 'zone_id', 'stop_url',\n",
       "       'location_type', 'parent_station', 'stop_timezone', 'trip_start_time',\n",
       "       'route_id', 'direction_id', 'trip_headsign', 'shape_id',\n",
       "       'route_short_name', 'route_desc'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_dict['aggregated'].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-13T05:21:25.869102Z",
     "start_time": "2019-06-13T05:21:25.838821Z"
    }
   },
   "outputs": [],
   "source": [
    "# suffix for the output files specifying the date range they contain; \n",
    "# we could get this from date_start_end_dict \n",
    "# here's a gross way to get min/max date - please make it better :)\n",
    "date_list = []\n",
    "for key, vals in date_start_end_dict.items():\n",
    "    date_list.append(datetime.datetime.strptime(vals[0],\"%Y-%m-%d\"))\n",
    "    date_list.append(datetime.datetime.strptime(vals[0],\"%Y-%m-%d\"))\n",
    "date_list.sort()\n",
    "start_date = date_list[0].strftime(\"%Y-%m-%d\")\n",
    "end_date = date_list[-1].strftime(\"%Y-%m-%d\")\n",
    "out_suffix = f\"{start_date}_{end_date}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-13T05:21:31.246243Z",
     "start_time": "2019-06-13T05:21:31.226844Z"
    }
   },
   "outputs": [],
   "source": [
    "#output folder\n",
    "gtfs_output_folder = \"../data/gtfs_merge/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-13T05:27:40.030174Z",
     "start_time": "2019-06-13T05:21:32.456995Z"
    }
   },
   "outputs": [],
   "source": [
    "# write output csv files\n",
    "file_dict['aggregated'].to_csv(f\"{gtfs_output_folder}gtfs_agg_{out_suffix}.csv\", index=False)\n",
    "file_dict['shapes'].to_csv(f\"{gtfs_output_folder}gtfs_shapes_{out_suffix}.csv\", index=False)\n",
    "file_dict['routes'].to_csv(f\"{gtfs_output_folder}gtfs_routes_{out_suffix}.csv\", index=False)\n",
    "file_dict['trips'].to_csv(f\"{gtfs_output_folder}gtfs_trips_{out_suffix}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
