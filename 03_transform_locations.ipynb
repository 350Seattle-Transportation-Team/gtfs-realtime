{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# importing matplotlib for plotting at the bottom of this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-06T05:07:45.941741Z",
     "start_time": "2020-01-06T05:07:37.588276Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from shapely.geometry import Point\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import time\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-06T05:07:46.125296Z",
     "start_time": "2020-01-06T05:07:45.945128Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "02/02/2020 23:40\n",
      "root\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime #added for Windows users\n",
    "current_time = datetime.now() #added for Windows users\n",
    "#!date #did not work on Windows\n",
    "print(current_time.strftime('%m/%d/%Y %H:%M'))\n",
    "!whoami"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load in all functions from `route_shape_process_scripts.py` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/work/gtfs-realtime'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-06T05:07:51.565398Z",
     "start_time": "2020-01-06T05:07:50.964653Z"
    }
   },
   "outputs": [],
   "source": [
    "import route_shape_process_scripts as f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General transformation flow in this notebook:\n",
    "- import gtfs files\n",
    "- pick a route of interest\n",
    "- grab position files for all routes\n",
    "- filter positions for only that route\n",
    "- add time index (this is used to break up positions by datetime and join with gtfs)\n",
    "- get popular shape in both route directions (direction_id)\n",
    "- make a route_vertex geopandas dataframe - we'll use this to find \"nearest\" route node\n",
    "- take all positions and find closest route node\n",
    "- append route info (distance traveled / shape_pt_sequence)\n",
    "- create timing metrics based on `trip_start_time` and `time_pct` <- position observation time - converted to Pacific"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import gtfs from 01_gtfs_transform notebook output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-06T05:07:56.102436Z",
     "start_time": "2020-01-06T05:07:56.052535Z"
    }
   },
   "outputs": [],
   "source": [
    "#if you ran notebook 01_gtfs this path should be correct\n",
    "gtfs_merge_file_path = \"./data/gtfs_merge/\"\n",
    "agg_filename = [f for f in listdir(gtfs_merge_file_path) if isfile(join(gtfs_merge_file_path, f)) \n",
    "                and 'agg' in f][0]\n",
    "routes_filename = [f for f in listdir(gtfs_merge_file_path) if isfile(join(gtfs_merge_file_path, f)) \n",
    "                and 'routes' in f][0]\n",
    "shapes_filename = [f for f in listdir(gtfs_merge_file_path) if isfile(join(gtfs_merge_file_path, f)) \n",
    "                and 'shapes' in f][0]\n",
    "trips_filename = [f for f in listdir(gtfs_merge_file_path) if isfile(join(gtfs_merge_file_path, f)) \n",
    "                and 'trips' in f][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-06T05:08:41.437390Z",
     "start_time": "2020-01-06T05:07:56.960894Z"
    }
   },
   "outputs": [],
   "source": [
    "full_routes_gtfs = pd.read_csv(f\"{gtfs_merge_file_path}{routes_filename}\", low_memory=False)\n",
    "full_shapes_gtfs = pd.read_csv(f\"{gtfs_merge_file_path}{shapes_filename}\", low_memory=False)\n",
    "full_trips_gtfs = pd.read_csv(f\"{gtfs_merge_file_path}{trips_filename}\", low_memory=False)\n",
    "full_trip_stop_schedule = pd.read_csv(f\"{gtfs_merge_file_path}{agg_filename}\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-06T05:08:46.786403Z",
     "start_time": "2020-01-06T05:08:41.442482Z"
    }
   },
   "outputs": [],
   "source": [
    "tripid_w_starttime = full_trip_stop_schedule.groupby('trip_id')\\\n",
    "                        .agg({'trip_start_time':'min'})\\\n",
    "                        .reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# break up the gtfs by `start date` and `end date`. TODO: there is a better way to do this. Right now, we want to make sure the vehicle position observation is joined with the `right` gtfs information. The simplest way to do that is to break up the position file by date and break up the gtfs by date and only join where the date windows match. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-06T05:08:48.021081Z",
     "start_time": "2020-01-06T05:08:46.789701Z"
    }
   },
   "outputs": [],
   "source": [
    "full_trip_stop_schedule_dict = {}\n",
    "for name, group in full_trip_stop_schedule.groupby(['start_gtfs_date','end_gtfs_date']):\n",
    "    full_trip_stop_schedule_dict[name] = group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get route name -- id dictionary. Nathaniel has a better class for this in `/data_transformations` but I haven't incorporated it yet. the below dictionary works as a quick/dirty way to input `route_short_name` and output `route_id`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-06T05:08:48.075792Z",
     "start_time": "2020-01-06T05:08:48.023931Z"
    }
   },
   "outputs": [],
   "source": [
    "route_name_to_id_dict = dict(zip(full_routes_gtfs.route_short_name.tolist(),\n",
    "                                 full_routes_gtfs.route_id.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-06T05:08:48.121732Z",
     "start_time": "2020-01-06T05:08:48.078451Z"
    }
   },
   "outputs": [],
   "source": [
    "route_id_to_name_dict = dict(zip(full_routes_gtfs.route_id.tolist(),\n",
    "                                 full_routes_gtfs.route_short_name.tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## select a route"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-06T05:08:50.331791Z",
     "start_time": "2020-01-06T05:08:50.275436Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100263"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get_select_routeid_name(full_routes_gtfs, ['E Line'])[2]\n",
    "route_of_interest = '7'\n",
    "route_of_interest_id = route_name_to_id_dict[route_of_interest]\n",
    "route_of_interest_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get all position files for these months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-06T05:08:59.175880Z",
     "start_time": "2020-01-06T05:08:51.599319Z"
    }
   },
   "outputs": [],
   "source": [
    "position_file_location = \"./data/intermed/\"\n",
    "position_date = \"201905\"\n",
    "# month_list = ['201809', '201810', '201811']\n",
    "# full_route_positions = get_positions_months(month_list, position_file_location)\n",
    "full_route_positions = pd.read_hdf(f\"{position_file_location}positions_{position_date}.h5\",low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# take only the positions for the choosen route_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-06T05:09:00.233648Z",
     "start_time": "2020-01-06T05:08:59.180134Z"
    }
   },
   "outputs": [],
   "source": [
    "single_route_positions = full_route_positions[\n",
    "                        full_route_positions['route_id']==route_of_interest_id].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# make sure the route dataframe is not empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-06T05:09:00.280773Z",
     "start_time": "2020-01-06T05:09:00.235935Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_route_positions.empty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# add time index columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-06T05:09:00.678917Z",
     "start_time": "2020-01-06T05:09:00.283843Z"
    }
   },
   "outputs": [],
   "source": [
    "#single_route_positions = f1.convert_index_to_pct(single_route_positions)\n",
    "single_route_positions = f1.add_time_index_columns(single_route_positions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# find the most popular shape on that route id going in one direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-06T05:09:03.770717Z",
     "start_time": "2020-01-06T05:09:03.599549Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10007006"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "direction = 1\n",
    "shape_of_interest_id, trip_headsign = f1.get_most_used_shape_id_per_direction(full_trip_stop_schedule, \n",
    "                                                                           route_of_interest_id, \n",
    "                                                                           direction)\n",
    "shape_of_interest_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# make one route_vertex_geo from shape_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-06T05:09:04.800257Z",
     "start_time": "2020-01-06T05:09:04.715778Z"
    }
   },
   "outputs": [],
   "source": [
    "route_vertex_geo = f1.make_geopandas_shape_df(full_shapes_gtfs, shape_of_interest_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# join position table with trip gtfs information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-06T05:09:18.842211Z",
     "start_time": "2020-01-06T05:09:05.517419Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('2019-04-20', '2019-05-08')\n",
      "('2019-05-09', '2019-06-18')\n"
     ]
    }
   ],
   "source": [
    "positions_w_trips = {}\n",
    "for name, group in full_trips_gtfs.groupby(['start_gtfs_date','end_gtfs_date']):\n",
    "    print(name)\n",
    "    positions_w_trips[name] = f1.join_positions_with_gtfs_trips(single_route_positions, group, name[0], name[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# merge all dictionaries into one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-06T05:09:19.001238Z",
     "start_time": "2020-01-06T05:09:18.844814Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('2019-04-20', '2019-05-08')\n",
      "('2019-05-09', '2019-06-18')\n"
     ]
    }
   ],
   "source": [
    "for idx, dict_group in enumerate(positions_w_trips.keys()):\n",
    "    print(dict_group)\n",
    "    if positions_w_trips[dict_group].empty:\n",
    "        pass\n",
    "    else:\n",
    "        if idx == 0:\n",
    "            unpacked_positions_full = positions_w_trips[dict_group].copy()\n",
    "        else:\n",
    "            unpacked_positions_full = unpacked_positions_full.append(positions_w_trips[dict_group])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# only take positions along one `shape_id`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-06T05:09:20.839895Z",
     "start_time": "2020-01-06T05:09:20.698407Z"
    }
   },
   "outputs": [],
   "source": [
    "unpacked_positions_one_shape = unpacked_positions_full[unpacked_positions_full['shape_id']==shape_of_interest_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# try parallel below - I don't think the parallel function will work on a Windows computer (I've had trouble in the past). It should work fine on a Mac."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### the below takes ~1-2 minutes on my computer depending on the shape/number of trips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-06T05:10:07.706801Z",
     "start_time": "2020-01-06T05:09:41.666481Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70.69993782043457\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    start = time.time()\n",
    "    positions_w_near_node_df = f1.get_close_node_process(unpacked_positions_one_shape, route_vertex_geo)\n",
    "    end = time.time()\n",
    "    print(end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# convert `time_pct` to Pacific time for datetime tranforms below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-06T05:10:18.342763Z",
     "start_time": "2020-01-06T05:10:11.398816Z"
    }
   },
   "outputs": [],
   "source": [
    "positions_w_near_node_datetime = f1.datetime_transform_df(positions_w_near_node_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-06T05:10:38.024461Z",
     "start_time": "2020-01-06T05:10:18.345049Z"
    }
   },
   "outputs": [],
   "source": [
    "position_w_node_schedule = f1.join_tripstart(positions_w_near_node_datetime, \n",
    "                                                            full_trip_stop_schedule, \n",
    "                                                            tripid_w_starttime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-06T05:10:45.144404Z",
     "start_time": "2020-01-06T05:10:38.027295Z"
    }
   },
   "outputs": [],
   "source": [
    "position_w_node_schedule['distance_btw_veh_and_shape'] = position_w_node_schedule\\\n",
    "                                                                .apply(lambda x: f1.calc_distance(x['vehicle_lat'],\n",
    "                                                                x['vehicle_long'], \n",
    "                                                                x['shape_pt_lat'],\n",
    "                                                               x['shape_pt_lon']), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## add in Nathaniel's code for finding closest point on route"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-06T05:10:45.195874Z",
     "start_time": "2020-01-06T05:10:45.146971Z"
    }
   },
   "outputs": [],
   "source": [
    "import find_closest_route_point as f2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-06T05:10:48.260715Z",
     "start_time": "2020-01-06T05:10:48.187809Z"
    }
   },
   "outputs": [],
   "source": [
    "position_w_node_schedule.drop(['index'], axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-06T05:10:48.621776Z",
     "start_time": "2020-01-06T05:10:48.589692Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65958, 34)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "position_w_node_schedule.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-06T05:14:42.952066Z",
     "start_time": "2020-01-06T05:10:49.158970Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "410.31353735923767\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    start = time.time()\n",
    "    position_w_closest_df = f2.get_closeset_point_process(position_w_node_schedule, full_shapes_gtfs, shape_of_interest_id)\n",
    "    end = time.time()\n",
    "    print(end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## unpack the tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-05T14:43:44.404884Z",
     "start_time": "2019-12-05T14:43:44.088488Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "position_w_closest_df['closest_pt_coords'] = position_w_closest_df['closest_pt_on_route_tuple'].apply(lambda x: x[0])\n",
    "position_w_closest_df['shape_dist_traveled_to_closest_pt'] = position_w_closest_df['closest_pt_on_route_tuple'].apply(lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-05T14:43:44.758567Z",
     "start_time": "2019-12-05T14:43:44.421956Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "position_w_closest_df.drop(['closest_pt_on_route_tuple'], axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "veh_dist_to_shape_std_dev = position_w_closest_df['distance_btw_veh_and_shape'].describe()['std']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filtered_position_w_node_schedule = position_w_closest_df[position_w_closest_df['distance_btw_veh_and_shape']\n",
    "                                                          <100].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#output folder\n",
    "output_folder = \"./data/transformed/\"\n",
    "filtered_position_w_node_schedule.to_csv(f\"{output_folder}route_{route_of_interest}_{position_date}.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
