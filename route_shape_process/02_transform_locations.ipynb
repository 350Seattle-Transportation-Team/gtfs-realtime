{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-06T03:16:03.222379Z",
     "start_time": "2019-05-06T03:16:03.096850Z"
    }
   },
   "outputs": [],
   "source": [
    "from route_shape_process_scripts import *\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import datetime\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import gtfs from 01_gtfs_transform notebook output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-12T19:01:37.721891Z",
     "start_time": "2019-05-12T19:00:56.119535Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminmalnor/anaconda2/envs/geopy36/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2728: DtypeWarning: Columns (5,26) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "full_routes_gtfs = pd.read_csv(\"input_gtfs/gtfs_routes_2018-08-15_2018-12-12.csv\")\n",
    "full_shapes_gtfs = pd.read_csv(\"input_gtfs/gtfs_shapes_2018-08-15_2018-12-12.csv\")\n",
    "full_trips_gtfs = pd.read_csv(\"input_gtfs/gtfs_trips_2018-08-15_2018-12-12.csv\")\n",
    "full_trip_stop_schedule = pd.read_csv(\"input_gtfs/gtfs_2018-08-15_2018-12-12.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-06T01:41:33.017868Z",
     "start_time": "2019-05-06T01:41:29.805941Z"
    }
   },
   "outputs": [],
   "source": [
    "full_trip_stop_schedule_dict = {}\n",
    "for name, group in full_trip_stop_schedule.groupby(['start_gtfs_date','end_gtfs_date']):\n",
    "    full_trip_stop_schedule_dict[name] = group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# analyze September --> November"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get route name -- id dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-06T01:43:56.255006Z",
     "start_time": "2019-05-06T01:43:56.223987Z"
    }
   },
   "outputs": [],
   "source": [
    "route_name_to_id_dict = dict(zip(full_routes_gtfs.route_short_name.tolist(),full_routes_gtfs.route_id.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-12T18:23:10.795254Z",
     "start_time": "2019-05-12T18:23:10.758717Z"
    }
   },
   "outputs": [],
   "source": [
    "routes_to_remove = ['South Lake Union Streetcar',\n",
    "                   'First Hill Streetcar',\n",
    "                   'Redmond LOOP',\n",
    "                   'Trailhead Direct Issaquah Alps',\n",
    "                   'Trailhead Direct Mt. Si',\n",
    "                  'Trailhead Direct Mailbox Peak',\n",
    "                  'Link light rail' ]\n",
    "for routes in routes_to_remove:\n",
    "    del route_name_to_id_dict[routes]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## select a route"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-12T18:23:22.629968Z",
     "start_time": "2019-05-12T18:23:22.593636Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'route_id': 100019}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get_select_routeid_name(full_routes_gtfs, ['E Line'])[2]\n",
    "route_of_interest = '120'\n",
    "route_of_interest_id = route_name_to_id_dict[route_of_interest]\n",
    "input_dict = {'route_id':route_of_interest_id}\n",
    "input_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get subset of position files for just one route_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-12T18:24:07.448546Z",
     "start_time": "2019-05-12T18:23:58.144290Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201809 9263521 Index(['route_id', 'timestamp', 'trip_id', 'vehicle_id', 'vehicle_lat',\n",
      "       'vehicle_long', 'time_utc', 'time_pct'],\n",
      "      dtype='object')\n",
      "201810 10655967 Index(['route_id', 'timestamp', 'trip_id', 'vehicle_id', 'vehicle_lat',\n",
      "       'vehicle_long', 'time_utc', 'time_pct'],\n",
      "      dtype='object')\n",
      "201811 10175465 Index(['route_id', 'timestamp', 'trip_id', 'vehicle_id', 'vehicle_lat',\n",
      "       'vehicle_long', 'time_utc', 'time_pct'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "month_list = ['201809', '201810', '201811']\n",
    "full_route_positions = get_positions_months_route_id(month_list, input_dict['route_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# add time index columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-12T18:24:15.257587Z",
     "start_time": "2019-05-12T18:24:14.571293Z"
    }
   },
   "outputs": [],
   "source": [
    "full_route_positions = convert_index_to_pct(full_route_positions)\n",
    "full_route_positions = add_time_index_columns(full_route_positions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# need to print out shape_ids - find the shape to process\n",
    "***\n",
    "# TODO - get direction id get edges for all shapes but keep shape_id column for filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-12T18:25:13.778307Z",
     "start_time": "2019-05-12T18:25:13.498156Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "full_df = pd.DataFrame()\n",
    "for name, group in full_trip_stop_schedule[full_trip_stop_schedule['route_id'] == input_dict['route_id']].groupby(['start_gtfs_date','end_gtfs_date']):\n",
    "    #print(name)\n",
    "    temp_df = group.groupby(['shape_id', 'direction_id','trip_headsign']).agg({'shape_id':'count'})\\\n",
    "                            .rename(columns={'shape_id':'shape_id_count'})\\\n",
    "                            .reset_index()\n",
    "    #print(temp_df)\n",
    "    if full_df.empty:\n",
    "        full_df = temp_df\n",
    "    else:\n",
    "        full_df = full_df.append(temp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-12T18:25:17.339916Z",
     "start_time": "2019-05-12T18:25:17.302051Z"
    }
   },
   "outputs": [],
   "source": [
    "full_df_sorted = full_df.groupby(['shape_id','direction_id','trip_headsign'])\\\n",
    "                .agg({'shape_id_count':'sum'})\\\n",
    "                .reset_index()\\\n",
    "                .sort_values('shape_id_count', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-12T18:46:32.084922Z",
     "start_time": "2019-05-12T18:46:32.051725Z"
    }
   },
   "outputs": [],
   "source": [
    "input_dict['direction_id']= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-12T18:46:32.513831Z",
     "start_time": "2019-05-12T18:46:32.479968Z"
    }
   },
   "outputs": [],
   "source": [
    "input_dict['shape_id'] = full_df_sorted.loc[full_df_sorted['direction_id']==input_dict['direction_id']].iloc[0]['shape_id']\n",
    "trip_headsign = full_df_sorted.loc[full_df_sorted['direction_id']==direction_id].iloc[0]['trip_headsign']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# make route_vertex_geo_dict and G_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-12T18:46:33.445042Z",
     "start_time": "2019-05-12T18:46:33.042019Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('2018-08-15', '2018-09-23')\n",
      "('2018-09-24', '2018-09-24')\n",
      "('2018-09-25', '2018-11-01')\n",
      "('2018-11-02', '2018-11-09')\n",
      "('2018-11-10', '2018-12-11')\n",
      "('2018-12-12', '2019-01-07')\n"
     ]
    }
   ],
   "source": [
    "route_vertex_geo_dict = {}\n",
    "G_dict = {}\n",
    "for name, group in full_shapes_gtfs.groupby(\n",
    "                ['start_gtfs_date','end_gtfs_date']):\n",
    "    print(name)\n",
    "    route_vertex_geo_dict[name], G_dict[name] = get_route_vertex_graph(group, input_dict['shape_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# join position table with trip gtfs information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-12T18:46:34.915933Z",
     "start_time": "2019-05-12T18:46:34.122242Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('2018-08-15', '2018-09-23')\n",
      "('2018-09-24', '2018-09-24')\n",
      "('2018-09-25', '2018-11-01')\n",
      "('2018-11-02', '2018-11-09')\n",
      "('2018-11-10', '2018-12-11')\n",
      "('2018-12-12', '2019-01-07')\n"
     ]
    }
   ],
   "source": [
    "positions_w_trips = {}\n",
    "for name, group in full_trips_gtfs.groupby(['start_gtfs_date','end_gtfs_date']):\n",
    "    print(name)\n",
    "    positions_w_trips[name] = join_positions_with_gtfs_trips(full_route_positions, group, name[0], name[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get unique_trip_list_dict and positions_w_trips_geo_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-12T18:46:44.703477Z",
     "start_time": "2019-05-12T18:46:35.156340Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('2018-08-15', '2018-09-23')\n",
      "no trips\n",
      "('2018-09-24', '2018-09-24')\n",
      "no trips\n",
      "('2018-09-25', '2018-11-01')\n",
      "no trips\n",
      "('2018-11-02', '2018-11-09')\n",
      "('2018-11-10', '2018-12-11')\n",
      "('2018-12-12', '2019-01-07')\n",
      "no trips\n"
     ]
    }
   ],
   "source": [
    "unique_trip_list_dict = {}\n",
    "positions_w_trips_geo_dict = {}\n",
    "\n",
    "for gtfs_groups in positions_w_trips.keys():\n",
    "    print(gtfs_groups)\n",
    "    unique_trip_list_dict[gtfs_groups], positions_w_trips_geo_dict[gtfs_groups] = get_trip_from_shape_id(input_dict['shape_id'], \n",
    "                                                                                                        positions_w_trips[gtfs_groups])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# try parallel below - I don't think the parallel function will work on a Windows computer (I've had trouble in the past). It should work fine on a Mac."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-12T18:46:44.750150Z",
     "start_time": "2019-05-12T18:46:44.705483Z"
    }
   },
   "outputs": [],
   "source": [
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-12T18:46:44.790231Z",
     "start_time": "2019-05-12T18:46:44.752551Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_close_node_parallel(df_group, route_vertex_geo):\n",
    "    '''\n",
    "    '''\n",
    "    df_group['close_node_tuple'] = df_group.apply(get_point_coords, route_vertex_geo=route_vertex_geo, axis=1).copy()\n",
    "    return df_group\n",
    "\n",
    "def get_point_coords(row, route_vertex_geo):\n",
    "    if isinstance(row['geometry'], float):\n",
    "        return ''\n",
    "    else:\n",
    "        return get_close_node(row['geometry'].coords[:][0], route_vertex_geo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-12T18:46:44.838206Z",
     "start_time": "2019-05-12T18:46:44.792348Z"
    }
   },
   "outputs": [],
   "source": [
    "def full_step_process():\n",
    "    n_pools = multiprocessing.cpu_count() - 1\n",
    "    pool = multiprocessing.Pool(n_pools)\n",
    "    positions_w_near_node_dict = {}\n",
    "    for gtfs_group in positions_w_trips.keys():\n",
    "        print(\"starting {}\".format(gtfs_group))\n",
    "        if positions_w_trips_geo_dict[gtfs_group].empty:\n",
    "            pass\n",
    "        else:\n",
    "            grouped = positions_w_trips_geo_dict[gtfs_group].groupby('month_day_trip_veh')\n",
    "            route_vertex_geo = route_vertex_geo_dict[gtfs_group]\n",
    "            trip_group_tuple_list = []\n",
    "            for name, group in grouped:\n",
    "                trip_group_tuple_list.append((group, route_vertex_geo))\n",
    "            positions_w_near_node_df = pd.concat(pool.starmap(get_close_node_parallel, trip_group_tuple_list))\n",
    "            positions_w_near_node_dict[gtfs_group] = positions_w_near_node_df\n",
    "    return positions_w_near_node_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# the below takes ~2-15 minutes on my computer depending on the shape/number of trips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-12T18:50:31.790626Z",
     "start_time": "2019-05-12T18:46:44.840427Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting ('2018-08-15', '2018-09-23')\n",
      "starting ('2018-09-24', '2018-09-24')\n",
      "starting ('2018-09-25', '2018-11-01')\n",
      "starting ('2018-11-02', '2018-11-09')\n",
      "starting ('2018-11-10', '2018-12-11')\n",
      "starting ('2018-12-12', '2019-01-07')\n",
      "226.91356778144836\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    start = time.time()\n",
    "    positions_w_near_node_dict = full_step_process()\n",
    "    end = time.time()\n",
    "    print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-12T18:50:31.857584Z",
     "start_time": "2019-05-12T18:50:31.792882Z"
    }
   },
   "outputs": [],
   "source": [
    "def unpack_near_node_column(positions_w_near_node_dict):\n",
    "    for gtfs_group in positions_w_near_node_dict.keys():\n",
    "        positions_w_near_node_dict[gtfs_group]['near_node_pt'] = positions_w_near_node_dict[gtfs_group].apply(lambda x: x['close_node_tuple'][0], axis=1)\n",
    "        positions_w_near_node_dict[gtfs_group]['shape_pt_sequence'] = positions_w_near_node_dict[gtfs_group].apply(lambda x: x['close_node_tuple'][1], axis=1)\n",
    "        positions_w_near_node_dict[gtfs_group]['dist_to_nearest_route_pt'] = positions_w_near_node_dict[gtfs_group].apply(lambda x: x['close_node_tuple'][2], axis=1)\n",
    "        positions_w_near_node_dict[gtfs_group].drop('close_node_tuple', axis=1, inplace=True)\n",
    "        positions_w_near_node_dict[gtfs_group].drop_duplicates(['month_day_trip_veh','shape_pt_sequence'], keep='last', inplace=True)\n",
    "    return positions_w_near_node_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-12T18:50:37.163911Z",
     "start_time": "2019-05-12T18:50:31.860221Z"
    }
   },
   "outputs": [],
   "source": [
    "unpacked_positions_w_near_node_dict = unpack_near_node_column(positions_w_near_node_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# merge all dictionaries into one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-12T18:50:37.311637Z",
     "start_time": "2019-05-12T18:50:37.166224Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('2018-11-02', '2018-11-09')\n",
      "('2018-11-10', '2018-12-11')\n"
     ]
    }
   ],
   "source": [
    "for idx, dict_group in enumerate(unpacked_positions_w_near_node_dict.keys()):\n",
    "    print(dict_group)\n",
    "    if idx == 0:\n",
    "        unpacked_positions_full = unpacked_positions_w_near_node_dict[dict_group].copy()\n",
    "    else:\n",
    "        unpacked_positions_full = unpacked_positions_full.append(unpacked_positions_w_near_node_dict[dict_group])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-12T18:58:28.354952Z",
     "start_time": "2019-05-12T18:58:24.570491Z"
    }
   },
   "outputs": [],
   "source": [
    "unpacked_positions_full.to_csv('transformed/route_{}_{}_shape_{}_raw_w_nearest_2018-08-15_2018-12-11.csv'.format(\n",
    "                                        route_of_interest,\"\".join(trip_headsign.split(\" \")) ,input_dict['shape_id']), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get start of schedue time (join in gtfs) then calculate just timing to shape distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-12T18:50:40.654739Z",
     "start_time": "2019-05-12T18:50:40.606322Z"
    }
   },
   "outputs": [],
   "source": [
    "def datetime_transform_df(df):\n",
    "    '''\n",
    "    '''\n",
    "    df['time_pct'] = df['time_pct'].apply(pd.to_datetime)\n",
    "    df.set_index('time_pct', inplace=True)\n",
    "    df.sort_index(inplace=True)\n",
    "    df = df.tz_localize('UTC')\n",
    "    df = df.tz_convert('US/Pacific')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-12T18:50:40.715463Z",
     "start_time": "2019-05-12T18:50:40.656893Z"
    }
   },
   "outputs": [],
   "source": [
    "def join_tripstart_unpacked(unpacked_positions_w_near_node_df, trip_stops_w_name_route):\n",
    "    '''\n",
    "    '''\n",
    "    normal_hours = [6,7,8,9,10,11,12,13,14,15,16,17,18,19,20]\n",
    "    #drop hours near '0' because the hour comparison gets messed up - gtfs has hours > 23 :(\n",
    "    unpacked_positions_w_near_node_df = unpacked_positions_w_near_node_df[unpacked_positions_w_near_node_df.hour.isin(normal_hours)]\n",
    "    \n",
    "    if 'trip_stops_w_name_route' in trip_stops_w_name_route.columns:\n",
    "        trip_stops_w_name_route.drop('trip_stops_w_name_route', axis=1, inplace=True)\n",
    "    position_w_node_schedule = unpacked_positions_w_near_node_df.merge(trip_stops_w_name_route,how='left',\n",
    "                                                    left_on=['trip_id','route_id','shape_id','shape_pt_sequence'], \n",
    "                                                    right_on=['trip_id','route_id','shape_id','stop_sequence'])\n",
    "    \n",
    "    position_w_node_schedule = position_w_node_schedule[position_w_node_schedule['stop_name'].notnull()]\n",
    "    \n",
    "    \n",
    "    \n",
    "    position_w_node_schedule = datetime_transform_df(position_w_node_schedule)\n",
    "    \n",
    "    position_w_node_schedule.drop_duplicates(['month_day_trip_veh','shape_pt_sequence'], keep='last', inplace=True)\n",
    "\n",
    "    position_w_node_schedule['trip_start_time'] = position_w_node_schedule['trip_start_time'].apply(pd.to_datetime)\n",
    "        \n",
    "    #take the time at every stop and subtract the scheduled start time\n",
    "    position_w_node_schedule['time_from_scheduled_start'] = (((position_w_node_schedule.index.hour)*60+\n",
    "                                                    position_w_node_schedule.index.minute+\n",
    "                                                    (position_w_node_schedule.index.second)/60) - \n",
    "                                                    ((position_w_node_schedule.loc[:,'trip_start_time'].dt.hour)*60+\n",
    "                                                    position_w_node_schedule.loc[:,'trip_start_time'].dt.minute+\n",
    "                                                    (position_w_node_schedule.loc[:,'trip_start_time'].dt.second)/60))\n",
    "\n",
    "    return position_w_node_schedule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# could be done in parallel!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-12T18:50:59.359691Z",
     "start_time": "2019-05-12T18:50:40.717817Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.61123776435852\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "unpacked_positions_full_w_start = join_tripstart_unpacked(unpacked_positions_full, full_trip_stop_schedule)\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-12T18:58:34.265110Z",
     "start_time": "2019-05-12T18:58:31.230725Z"
    }
   },
   "outputs": [],
   "source": [
    "unpacked_positions_full_w_start.to_csv('transformed/route_{}_{}_shape_{}_stopsonly_2018-08-15_2018-12-11.csv'.format(\n",
    "                                        route_of_interest,\"\".join(trip_headsign.split(\" \")), input_dict['shape_id']), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
